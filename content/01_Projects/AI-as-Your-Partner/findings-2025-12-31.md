---
title: Initial Findings - Rules File Analysis
description: First session discoveries about what makes AI rules personal vs. universal
tags:
  - ai
  - claude-code
  - methodology
  - analysis
---

# Initial Findings: Rules File Analysis

*Session: 2025-12-31*

## What We Examined

Your user-level Claude configuration at `~/.dotfiles/config/claude/`:

```
claude/
├── CLAUDE.md                    # 5-step workflow
└── rules/
    ├── development-basics.md    # Mandatory practices
    ├── workflows/
    │   ├── research-caching.md  # Persist fetched docs
    │   ├── testing-review.md    # Testing + review philosophy
    │   ├── git.md               # .gitignore + commit hygiene
    │   └── pull-requests.md     # Branching + PR workflow
    ├── python/
    │   └── setup.md             # Python project structure
    └── typescript/
        └── setup.md             # TypeScript project structure
```

---

## The Spectrum Model

Rules aren't binary (personal vs. universal). They exist on a spectrum:

```
UNIVERSAL ←—————————————————————————————————→ PERSONAL

"Don't commit       "Write tests"        "Use sub-agent
 secrets"           (universal value,     review"
                     personal commitment)
```

The interesting work is in the middle.

---

## Classification of Your Rules

### Universal (Defensive)

These prevent harm. Everyone should do them:

| Rule | Why Universal |
|------|---------------|
| Never commit secrets | Irreversible damage |
| Use .gitignore | Prevents repo pollution |
| Don't commit generated files | Prevents bloat |
| Run linters before commits | Catches obvious mistakes |

**Pattern**: Universal rules are about **avoiding disasters**.

### Personal (Generative)

These build capability. They reflect your choices:

| Rule | Why Personal |
|------|--------------|
| Use `uv` for Python | Many use pip/poetry |
| Use `bun` for TypeScript | Many use npm/yarn |
| Use `ruff` for linting | flake8/pylint still common |
| Cache research in `docs/research/` | Novel pattern; most don't do this |
| Sub-agent review with fresh context | I've never seen this elsewhere |
| ADRs as mandatory | Many teams skip entirely |
| "Automated reviewers are frequently wrong" | Earned skepticism |

**Pattern**: Personal rules are about **building capability**.

### The Middle Ground (Values as Rules)

These *sound* universal but encode commitment levels:

| Rule | The Tension |
|------|-------------|
| "A task is not complete until tests exist" | Many developers ship without tests |
| "All changes go on branches" | Solo devs often commit to main |
| "The specific style matters less than having one" | Some argue certain styles are objectively better |

**Pattern**: These encode *values* disguised as *practices*.

---

## The 5-Step Workflow: Your Most Personal Element

```
Research → Plan → Execute → Test → Review
```

This isn't a practice. It's a **methodology**. It encodes beliefs:

1. **Research before action**: Don't assume you know; verify first
2. **Planning is distinct from execution**: Think, then do (not simultaneously)
3. **Self-review is insufficient**: Fresh context catches what familiarity misses

This is a *way of thinking about work*, not a checklist.

### Why This Matters

Most "rules files" I've seen are technical: "use this tool," "format code this way." Yours starts with *how to approach problems*. That's different.

---

## Novel Patterns Worth Noting

### Research Caching

```markdown
- Store fetched documentation in `docs/research/` (create if missing)
- Save as markdown with frontmatter containing `description` and `download_date`
- Check `docs/research/` before fetching external documentation
- Refresh cached docs older than one week
```

This is genuinely unusual. It treats AI sessions as building persistent knowledge, not disposable conversations. **Knowledge compounds across sessions.**

### Sub-Agent Review

```markdown
- Use a sub-agent with fresh context to review at critical points
- The reviewer catches issues the implementer missed due to being too close to the work
```

This exploits a real property of AI: context shapes output. Fresh context = fresh eyes. You're using AI architecture as a feature, not fighting it.

### Skepticism of Automated Reviewers

```markdown
- Automated PR comments (GitHub Copilot, etc.) require validation
- Never accept suggestions at face value - audit each one
- Automated reviewers are frequently wrong; verify before applying
```

This reads like learned experience, not inherited wisdom. Something burned you.

---

## Open Questions for Future Sessions

1. **Can personal rules become universal?** If sub-agent review demonstrably works, should everyone adopt it?

2. **Are personal rules personality or experience?** Is "automated reviewers are frequently wrong" a trait or a scar?

3. **What's the cost of personalization?** Does a highly personal config make it harder to collaborate with others who don't share your methodology?

4. **What's missing?** What patterns do you follow that haven't been codified yet?

5. **Is "AI as partner" the right frame?** Or is it "AI as extension of self"? "AI as tool that fits your hand"?

---

## Tentative Thesis

**The best AI configurations aren't about making AI correct. They're about making AI *yours*.**

Universal rules are table stakes. Personal rules are where leverage lives.

---

## Next Steps Identified

- [x] Research community patterns (how do others structure AI rules?)
- [x] Dig into *why* the 5-step workflow feels right
- [x] Experiment: what breaks if you remove a personal rule?
- [ ] Interview yourself: what rules are implicit but not written?
